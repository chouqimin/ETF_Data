{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Big data\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 716 samples, validate on 80 samples\n",
      "Epoch 1/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.3929 - acc: 0.0014 - val_loss: 0.0092 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "716/716 [==============================] - 0s 331us/step - loss: 0.0736 - acc: 0.0014 - val_loss: 0.0830 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "716/716 [==============================] - 0s 302us/step - loss: 0.0484 - acc: 0.0014 - val_loss: 0.1087 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "716/716 [==============================] - 0s 276us/step - loss: 0.0386 - acc: 0.0014 - val_loss: 0.0310 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "716/716 [==============================] - 0s 280us/step - loss: 0.0148 - acc: 0.0014 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "716/716 [==============================] - 0s 283us/step - loss: 0.0082 - acc: 0.0028 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "716/716 [==============================] - 0s 269us/step - loss: 0.0072 - acc: 0.0028 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "716/716 [==============================] - 0s 275us/step - loss: 0.0078 - acc: 0.0028 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "716/716 [==============================] - 0s 267us/step - loss: 0.0064 - acc: 0.0028 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "716/716 [==============================] - 0s 269us/step - loss: 0.0069 - acc: 0.0028 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "716/716 [==============================] - 0s 269us/step - loss: 0.0063 - acc: 0.0028 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "716/716 [==============================] - 0s 264us/step - loss: 0.0069 - acc: 0.0028 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "716/716 [==============================] - 0s 269us/step - loss: 0.0059 - acc: 0.0028 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "716/716 [==============================] - 0s 265us/step - loss: 0.0058 - acc: 0.0028 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "716/716 [==============================] - 0s 271us/step - loss: 0.0059 - acc: 0.0028 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "716/716 [==============================] - 0s 271us/step - loss: 0.0059 - acc: 0.0028 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "716/716 [==============================] - 0s 261us/step - loss: 0.0058 - acc: 0.0028 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "716/716 [==============================] - 0s 260us/step - loss: 0.0058 - acc: 0.0028 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "716/716 [==============================] - 0s 259us/step - loss: 0.0057 - acc: 0.0028 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "716/716 [==============================] - 0s 269us/step - loss: 0.0063 - acc: 0.0028 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "716/716 [==============================] - 0s 262us/step - loss: 0.0058 - acc: 0.0028 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "716/716 [==============================] - 0s 263us/step - loss: 0.0060 - acc: 0.0028 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "716/716 [==============================] - 0s 259us/step - loss: 0.0052 - acc: 0.0028 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "716/716 [==============================] - 0s 264us/step - loss: 0.0053 - acc: 0.0028 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "716/716 [==============================] - 0s 262us/step - loss: 0.0061 - acc: 0.0028 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "716/716 [==============================] - 0s 264us/step - loss: 0.0068 - acc: 0.0028 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "716/716 [==============================] - 0s 263us/step - loss: 0.0058 - acc: 0.0028 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "716/716 [==============================] - 0s 263us/step - loss: 0.0056 - acc: 0.0028 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "716/716 [==============================] - 0s 311us/step - loss: 0.0058 - acc: 0.0028 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "716/716 [==============================] - 0s 297us/step - loss: 0.0050 - acc: 0.0028 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "716/716 [==============================] - 0s 271us/step - loss: 0.0048 - acc: 0.0028 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "716/716 [==============================] - 0s 271us/step - loss: 0.0048 - acc: 0.0028 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "716/716 [==============================] - 0s 265us/step - loss: 0.0051 - acc: 0.0028 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "716/716 [==============================] - 0s 269us/step - loss: 0.0049 - acc: 0.0028 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "716/716 [==============================] - 0s 270us/step - loss: 0.0050 - acc: 0.0028 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "716/716 [==============================] - 0s 278us/step - loss: 0.0051 - acc: 0.0028 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "716/716 [==============================] - 0s 270us/step - loss: 0.0055 - acc: 0.0028 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "716/716 [==============================] - 0s 265us/step - loss: 0.0050 - acc: 0.0028 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "716/716 [==============================] - 0s 265us/step - loss: 0.0043 - acc: 0.0028 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "716/716 [==============================] - 0s 266us/step - loss: 0.0046 - acc: 0.0028 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "716/716 [==============================] - 0s 269us/step - loss: 0.0051 - acc: 0.0028 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "716/716 [==============================] - 0s 267us/step - loss: 0.0044 - acc: 0.0028 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "716/716 [==============================] - 0s 264us/step - loss: 0.0046 - acc: 0.0028 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "716/716 [==============================] - 0s 266us/step - loss: 0.0046 - acc: 0.0028 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "716/716 [==============================] - 0s 264us/step - loss: 0.0044 - acc: 0.0028 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "716/716 [==============================] - 0s 268us/step - loss: 0.0046 - acc: 0.0028 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "716/716 [==============================] - 0s 264us/step - loss: 0.0046 - acc: 0.0028 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "716/716 [==============================] - 0s 266us/step - loss: 0.0049 - acc: 0.0028 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "716/716 [==============================] - 0s 265us/step - loss: 0.0045 - acc: 0.0028 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "716/716 [==============================] - 0s 267us/step - loss: 0.0046 - acc: 0.0028 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "716/716 [==============================] - 0s 269us/step - loss: 0.0044 - acc: 0.0028 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "716/716 [==============================] - 0s 270us/step - loss: 0.0040 - acc: 0.0028 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "716/716 [==============================] - 0s 252us/step - loss: 0.0048 - acc: 0.0028 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "716/716 [==============================] - 0s 266us/step - loss: 0.0040 - acc: 0.0028 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "716/716 [==============================] - 0s 269us/step - loss: 0.0048 - acc: 0.0028 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "716/716 [==============================] - 0s 311us/step - loss: 0.0038 - acc: 0.0028 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "716/716 [==============================] - 0s 301us/step - loss: 0.0041 - acc: 0.0028 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "716/716 [==============================] - 0s 299us/step - loss: 0.0039 - acc: 0.0028 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "716/716 [==============================] - 0s 292us/step - loss: 0.0045 - acc: 0.0028 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "716/716 [==============================] - 0s 262us/step - loss: 0.0041 - acc: 0.0028 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "716/716 [==============================] - 0s 264us/step - loss: 0.0038 - acc: 0.0028 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "716/716 [==============================] - 0s 262us/step - loss: 0.0043 - acc: 0.0028 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "716/716 [==============================] - 0s 262us/step - loss: 0.0042 - acc: 0.0028 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "716/716 [==============================] - 0s 266us/step - loss: 0.0037 - acc: 0.0028 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "716/716 [==============================] - 0s 259us/step - loss: 0.0036 - acc: 0.0028 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "716/716 [==============================] - 0s 262us/step - loss: 0.0035 - acc: 0.0028 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "716/716 [==============================] - 0s 260us/step - loss: 0.0034 - acc: 0.0028 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "716/716 [==============================] - 0s 262us/step - loss: 0.0035 - acc: 0.0028 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "716/716 [==============================] - 0s 260us/step - loss: 0.0039 - acc: 0.0028 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "716/716 [==============================] - 0s 259us/step - loss: 0.0036 - acc: 0.0028 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "716/716 [==============================] - 0s 259us/step - loss: 0.0039 - acc: 0.0028 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "716/716 [==============================] - 0s 261us/step - loss: 0.0035 - acc: 0.0028 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "716/716 [==============================] - 0s 259us/step - loss: 0.0033 - acc: 0.0028 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "716/716 [==============================] - 0s 260us/step - loss: 0.0031 - acc: 0.0028 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "716/716 [==============================] - 0s 259us/step - loss: 0.0027 - acc: 0.0028 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "716/716 [==============================] - 0s 259us/step - loss: 0.0033 - acc: 0.0028 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "716/716 [==============================] - 0s 264us/step - loss: 0.0028 - acc: 0.0028 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "716/716 [==============================] - 0s 261us/step - loss: 0.0032 - acc: 0.0028 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "716/716 [==============================] - 0s 268us/step - loss: 0.0032 - acc: 0.0028 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "716/716 [==============================] - 0s 264us/step - loss: 0.0031 - acc: 0.0028 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "716/716 [==============================] - 0s 265us/step - loss: 0.0032 - acc: 0.0028 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "716/716 [==============================] - 0s 263us/step - loss: 0.0031 - acc: 0.0028 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "716/716 [==============================] - 0s 306us/step - loss: 0.0028 - acc: 0.0028 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "716/716 [==============================] - 0s 346us/step - loss: 0.0032 - acc: 0.0028 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "716/716 [==============================] - 0s 285us/step - loss: 0.0028 - acc: 0.0028 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "716/716 [==============================] - 0s 282us/step - loss: 0.0030 - acc: 0.0028 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "716/716 [==============================] - 0s 289us/step - loss: 0.0031 - acc: 0.0028 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "716/716 [==============================] - 0s 280us/step - loss: 0.0025 - acc: 0.0028 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "716/716 [==============================] - 0s 281us/step - loss: 0.0035 - acc: 0.0028 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "716/716 [==============================] - 0s 273us/step - loss: 0.0029 - acc: 0.0028 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "716/716 [==============================] - 0s 265us/step - loss: 0.0026 - acc: 0.0028 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "716/716 [==============================] - 0s 267us/step - loss: 0.0029 - acc: 0.0028 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "716/716 [==============================] - 0s 272us/step - loss: 0.0030 - acc: 0.0028 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "716/716 [==============================] - 0s 266us/step - loss: 0.0028 - acc: 0.0028 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "716/716 [==============================] - 0s 269us/step - loss: 0.0025 - acc: 0.0028 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "716/716 [==============================] - 0s 275us/step - loss: 0.0026 - acc: 0.0028 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "716/716 [==============================] - 0s 266us/step - loss: 0.0022 - acc: 0.0028 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "716/716 [==============================] - 0s 268us/step - loss: 0.0028 - acc: 0.0028 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "716/716 [==============================] - 0s 283us/step - loss: 0.0026 - acc: 0.0028 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "716/716 [==============================] - 0s 281us/step - loss: 0.0027 - acc: 0.0028 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Train on 716 samples, validate on 80 samples\n",
      "Epoch 1/100\n",
      "716/716 [==============================] - 0s 287us/step - loss: 0.0026 - acc: 0.0028 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "716/716 [==============================] - 0s 269us/step - loss: 0.0025 - acc: 0.0028 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "716/716 [==============================] - 0s 271us/step - loss: 0.0024 - acc: 0.0028 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "716/716 [==============================] - 0s 269us/step - loss: 0.0023 - acc: 0.0028 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "716/716 [==============================] - 0s 269us/step - loss: 0.0022 - acc: 0.0028 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "716/716 [==============================] - 0s 263us/step - loss: 0.0024 - acc: 0.0028 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "716/716 [==============================] - 0s 273us/step - loss: 0.0024 - acc: 0.0028 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "716/716 [==============================] - 0s 269us/step - loss: 0.0025 - acc: 0.0028 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "716/716 [==============================] - 0s 269us/step - loss: 0.0022 - acc: 0.0028 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "716/716 [==============================] - 0s 342us/step - loss: 0.0022 - acc: 0.0028 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "716/716 [==============================] - 0s 301us/step - loss: 0.0022 - acc: 0.0028 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "716/716 [==============================] - 0s 332us/step - loss: 0.0022 - acc: 0.0028 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "716/716 [==============================] - 0s 307us/step - loss: 0.0021 - acc: 0.0028 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "716/716 [==============================] - 0s 282us/step - loss: 0.0022 - acc: 0.0028 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "716/716 [==============================] - 0s 269us/step - loss: 0.0021 - acc: 0.0028 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "716/716 [==============================] - 0s 265us/step - loss: 0.0023 - acc: 0.0028 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "716/716 [==============================] - 0s 264us/step - loss: 0.0021 - acc: 0.0028 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "716/716 [==============================] - 0s 264us/step - loss: 0.0018 - acc: 0.0028 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "716/716 [==============================] - 0s 266us/step - loss: 0.0019 - acc: 0.0028 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "716/716 [==============================] - 0s 260us/step - loss: 0.0019 - acc: 0.0028 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "716/716 [==============================] - 0s 261us/step - loss: 0.0021 - acc: 0.0028 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "716/716 [==============================] - 0s 259us/step - loss: 0.0020 - acc: 0.0028 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "716/716 [==============================] - 0s 264us/step - loss: 0.0019 - acc: 0.0028 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "716/716 [==============================] - 0s 261us/step - loss: 0.0020 - acc: 0.0028 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "716/716 [==============================] - 0s 267us/step - loss: 0.0019 - acc: 0.0028 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "716/716 [==============================] - 0s 262us/step - loss: 0.0018 - acc: 0.0028 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "716/716 [==============================] - 0s 262us/step - loss: 0.0018 - acc: 0.0028 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "716/716 [==============================] - 0s 263us/step - loss: 0.0019 - acc: 0.0028 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "716/716 [==============================] - 0s 264us/step - loss: 0.0018 - acc: 0.0028 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "716/716 [==============================] - 0s 257us/step - loss: 0.0017 - acc: 0.0028 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "716/716 [==============================] - 0s 258us/step - loss: 0.0019 - acc: 0.0028 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "716/716 [==============================] - 0s 261us/step - loss: 0.0018 - acc: 0.0028 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "716/716 [==============================] - 0s 263us/step - loss: 0.0018 - acc: 0.0028 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "716/716 [==============================] - 0s 264us/step - loss: 0.0017 - acc: 0.0028 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "716/716 [==============================] - 0s 261us/step - loss: 0.0017 - acc: 0.0028 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "716/716 [==============================] - 0s 269us/step - loss: 0.0018 - acc: 0.0028 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "716/716 [==============================] - 0s 339us/step - loss: 0.0020 - acc: 0.0028 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "716/716 [==============================] - 0s 266us/step - loss: 0.0018 - acc: 0.0028 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "716/716 [==============================] - 0s 259us/step - loss: 0.0017 - acc: 0.0028 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "716/716 [==============================] - 0s 266us/step - loss: 0.0017 - acc: 0.0028 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "716/716 [==============================] - 0s 264us/step - loss: 0.0017 - acc: 0.0028 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "716/716 [==============================] - 0s 265us/step - loss: 0.0019 - acc: 0.0028 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "716/716 [==============================] - 0s 268us/step - loss: 0.0015 - acc: 0.0028 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "716/716 [==============================] - 0s 263us/step - loss: 0.0017 - acc: 0.0028 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "716/716 [==============================] - 0s 264us/step - loss: 0.0016 - acc: 0.0028 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "716/716 [==============================] - 0s 264us/step - loss: 0.0016 - acc: 0.0028 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "716/716 [==============================] - 0s 262us/step - loss: 0.0017 - acc: 0.0028 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "716/716 [==============================] - 0s 265us/step - loss: 0.0018 - acc: 0.0028 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "716/716 [==============================] - 0s 267us/step - loss: 0.0016 - acc: 0.0028 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "716/716 [==============================] - 0s 265us/step - loss: 0.0017 - acc: 0.0028 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "716/716 [==============================] - 0s 268us/step - loss: 0.0014 - acc: 0.0028 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "716/716 [==============================] - 0s 264us/step - loss: 0.0014 - acc: 0.0028 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "716/716 [==============================] - 0s 267us/step - loss: 0.0017 - acc: 0.0028 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "716/716 [==============================] - 0s 269us/step - loss: 0.0015 - acc: 0.0028 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "716/716 [==============================] - 0s 267us/step - loss: 0.0018 - acc: 0.0028 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "716/716 [==============================] - 0s 264us/step - loss: 0.0016 - acc: 0.0028 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "716/716 [==============================] - 0s 266us/step - loss: 0.0014 - acc: 0.0028 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "716/716 [==============================] - 0s 267us/step - loss: 0.0013 - acc: 0.0028 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "716/716 [==============================] - 0s 270us/step - loss: 0.0014 - acc: 0.0028 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "716/716 [==============================] - 0s 271us/step - loss: 0.0018 - acc: 0.0028 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "716/716 [==============================] - 0s 263us/step - loss: 0.0015 - acc: 0.0028 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "716/716 [==============================] - 0s 265us/step - loss: 0.0014 - acc: 0.0028 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "716/716 [==============================] - 0s 266us/step - loss: 0.0015 - acc: 0.0028 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "716/716 [==============================] - 0s 342us/step - loss: 0.0017 - acc: 0.0028 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "716/716 [==============================] - 0s 293us/step - loss: 0.0015 - acc: 0.0028 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "716/716 [==============================] - 0s 293us/step - loss: 0.0014 - acc: 0.0028 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "716/716 [==============================] - 0s 294us/step - loss: 0.0014 - acc: 0.0028 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "716/716 [==============================] - 0s 290us/step - loss: 0.0014 - acc: 0.0028 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "716/716 [==============================] - 0s 283us/step - loss: 0.0015 - acc: 0.0028 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "716/716 [==============================] - 0s 279us/step - loss: 0.0015 - acc: 0.0028 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "716/716 [==============================] - 0s 280us/step - loss: 0.0014 - acc: 0.0028 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "716/716 [==============================] - 0s 263us/step - loss: 0.0014 - acc: 0.0028 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "716/716 [==============================] - 0s 262us/step - loss: 0.0014 - acc: 0.0028 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "716/716 [==============================] - 0s 273us/step - loss: 0.0014 - acc: 0.0028 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "716/716 [==============================] - 0s 264us/step - loss: 0.0013 - acc: 0.0028 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "716/716 [==============================] - 0s 260us/step - loss: 0.0014 - acc: 0.0028 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "716/716 [==============================] - 0s 258us/step - loss: 0.0014 - acc: 0.0028 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "716/716 [==============================] - 0s 261us/step - loss: 0.0013 - acc: 0.0028 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "716/716 [==============================] - 0s 260us/step - loss: 0.0013 - acc: 0.0028 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "716/716 [==============================] - 0s 261us/step - loss: 0.0014 - acc: 0.0028 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "716/716 [==============================] - 0s 262us/step - loss: 0.0014 - acc: 0.0028 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "716/716 [==============================] - 0s 259us/step - loss: 0.0015 - acc: 0.0028 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "716/716 [==============================] - 0s 262us/step - loss: 0.0013 - acc: 0.0028 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "716/716 [==============================] - 0s 262us/step - loss: 0.0013 - acc: 0.0028 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "716/716 [==============================] - 0s 265us/step - loss: 0.0014 - acc: 0.0028 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "716/716 [==============================] - 0s 263us/step - loss: 0.0013 - acc: 0.0028 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "716/716 [==============================] - 0s 263us/step - loss: 0.0015 - acc: 0.0028 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "716/716 [==============================] - 0s 264us/step - loss: 0.0014 - acc: 0.0028 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "716/716 [==============================] - 0s 262us/step - loss: 0.0013 - acc: 0.0028 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "716/716 [==============================] - 0s 267us/step - loss: 0.0016 - acc: 0.0028 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "716/716 [==============================] - 0s 335us/step - loss: 0.0014 - acc: 0.0028 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "716/716 [==============================] - 0s 268us/step - loss: 0.0015 - acc: 0.0028 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "716/716 [==============================] - 0s 264us/step - loss: 0.0014 - acc: 0.0028 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "716/716 [==============================] - 0s 262us/step - loss: 0.0013 - acc: 0.0028 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "716/716 [==============================] - 0s 271us/step - loss: 0.0012 - acc: 0.0028 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "716/716 [==============================] - 0s 270us/step - loss: 0.0012 - acc: 0.0028 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "716/716 [==============================] - 0s 263us/step - loss: 0.0013 - acc: 0.0028 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "716/716 [==============================] - 0s 263us/step - loss: 0.0012 - acc: 0.0028 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "716/716 [==============================] - 0s 269us/step - loss: 0.0013 - acc: 0.0028 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "716/716 [==============================] - 0s 266us/step - loss: 0.0012 - acc: 0.0028 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 5, 50)             25600     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 5, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 5, 50)             20200     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 5, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                816       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 66,833\n",
      "Trainable params: 66,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "[{'class_name': 'LSTM', 'config': {'name': 'lstm_4', 'trainable': True, 'batch_input_shape': (None, 5, 77), 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'units': 50, 'activation': 'tanh', 'recurrent_activation': 'hard_sigmoid', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'recurrent_initializer': {'class_name': 'Orthogonal', 'config': {'gain': 1.0, 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'unit_forget_bias': True, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'implementation': 1}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_4', 'trainable': True, 'rate': 0.3, 'noise_shape': None, 'seed': None}}, {'class_name': 'LSTM', 'config': {'name': 'lstm_5', 'trainable': True, 'batch_input_shape': (None, 5, 77), 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'units': 50, 'activation': 'tanh', 'recurrent_activation': 'hard_sigmoid', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'recurrent_initializer': {'class_name': 'Orthogonal', 'config': {'gain': 1.0, 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'unit_forget_bias': True, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'implementation': 1}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_5', 'trainable': True, 'rate': 0.3, 'noise_shape': None, 'seed': None}}, {'class_name': 'LSTM', 'config': {'name': 'lstm_6', 'trainable': True, 'batch_input_shape': (None, 5, 77), 'dtype': 'float32', 'return_sequences': False, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'units': 50, 'activation': 'tanh', 'recurrent_activation': 'hard_sigmoid', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'recurrent_initializer': {'class_name': 'Orthogonal', 'config': {'gain': 1.0, 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'unit_forget_bias': True, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'implementation': 1}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_6', 'trainable': True, 'rate': 0.3, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_3', 'trainable': True, 'units': 16, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'RandomUniform', 'config': {'minval': -0.05, 'maxval': 0.05, 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_4', 'trainable': True, 'units': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'RandomUniform', 'config': {'minval': -0.05, 'maxval': 0.05, 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "796/796 [==============================] - 0s 72us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19db8263a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue May 15 11:36:54 2018\n",
    "\n",
    "@author: Ken\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "# Load files\n",
    "foxconndf= pd.read_csv('0051_1000.csv', index_col=0 )\n",
    "foxconndf.dropna(how='any',inplace=True)#date?\n",
    "\n",
    "#foxconndf = foxconndf.drop(['Date'], axis=1)\n",
    "\n",
    "TIME_STEPS = 5 #\n",
    "TRAIN_RATE = 0.8#train %\n",
    "CELL_SIZE = 50\n",
    "BATCH_SIZE = None\n",
    "EPOCHS_NUM = 100 #\n",
    "LAYERS_NUM = 2 #? total??\n",
    "DROPOUT_RATE = 0.3 #drop%\n",
    "FEATURE_NUM = len(foxconndf.columns) # Feature num\n",
    "\n",
    "def normalize(df):#\n",
    "    newdf= df.copy()\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    for feature in df.columns:\n",
    "        newdf[feature] = min_max_scaler.fit_transform(df[feature].values.reshape(-1,1))\n",
    "    return newdf\n",
    "foxconndf_norm= normalize(foxconndf)\n",
    "\n",
    "def data_helper(df, time_frame):\n",
    "    # Feature number\n",
    "    number_features = len(df.columns)\n",
    "    datavalue = df.as_matrix() #66x(column) * 918(row)(66x) , [[66x],[66x],....[66x]]\n",
    "    x_result = []    \n",
    "    y_result = []\n",
    "    for index in range(len(datavalue)-TIME_STEPS):\n",
    "        x_result.append(datavalue[index: index + time_frame])\n",
    "        y_result.append(datavalue[index + time_frame][4])  # test for closeprice time_stepclosepricey\n",
    "    # (time_step)x \n",
    "    #[ [[1st 66x],[2nd 66x],[3rd 66x],[4th 66x],[5th 66x]] , [[2nd 66x],[3rd 66x],[4th 66x],[5th 66x],[6th 66x]] ,....]\n",
    "    x_result = np.array(x_result)\n",
    "    y_result = np.array(y_result)#time_step+1closepricey\n",
    "\n",
    "    number_train = round(TRAIN_RATE * x_result.shape[0])\n",
    "    #list(x_train & x_test),x_train0~number_train ->[:number_train],x_textnumber_train~final ->[number_train:]\n",
    "    x_train, x_test = x_result[:int(number_train)], x_result[int(number_train) :]\n",
    "    y_train, y_test = y_result[:int(number_train)], y_result[int(number_train) :]\n",
    "    \n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], number_features))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], number_features))\n",
    "\n",
    "    return [x_train, y_train, x_test, y_test]\n",
    "\n",
    "X_train, y_train, X_test, y_test = data_helper(foxconndf_norm, TIME_STEPS)\n",
    "\n",
    "data_helper(foxconndf_norm, TIME_STEPS)\n",
    "\n",
    "\n",
    "def build_model(input_length, input_dim):\n",
    "    model = Sequential()\n",
    "    for _ in range(LAYERS_NUM):\n",
    "        model.add(LSTM(CELL_SIZE, input_shape=(input_length, input_dim), return_sequences=True))\n",
    "        model.add(Dropout(DROPOUT_RATE))\n",
    "    model.add(LSTM(CELL_SIZE, input_shape=(input_length, input_dim), return_sequences=False))\n",
    "    model.add(Dropout(DROPOUT_RATE))\n",
    "    model.add(Dense(16,kernel_initializer=\"uniform\",activation='relu'))\n",
    "    model.add(Dense(1,kernel_initializer=\"uniform\",activation='linear')) # CELL_SIZE 5, output dim\n",
    "    model.compile(loss='mse',optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = build_model( TIME_STEPS, FEATURE_NUM )\n",
    "model.fit( X_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS_NUM, validation_split=0.1, verbose=1)\n",
    "train_history=model.fit( X_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS_NUM, validation_split=0.1, verbose=1)\n",
    "\n",
    "pred = model.predict(X_test) # model.predict(data set)\n",
    "\n",
    "def denormalize(df, norm_value):\n",
    "    original_value = df['ClosePrice'].values.reshape(-1,1)\n",
    "    norm_value = norm_value.reshape(-1,1)\n",
    "\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    min_max_scaler.fit_transform(original_value)\n",
    "    denorm_value = min_max_scaler.inverse_transform(norm_value)\n",
    "\n",
    "    return denorm_value\n",
    "\n",
    "denorm_pred = denormalize(foxconndf, pred)\n",
    "denorm_ytest = denormalize(foxconndf, y_test)\n",
    "print(model.summary()) # model summary\n",
    "print(model.get_config()) # model configuration\n",
    "model.save('model_test_closeonly.h1')\n",
    "my_model = load_model('model_test_closeonly.h1')\n",
    "score = model.evaluate(X_train, y_train, batch_size=BATCH_SIZE)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline  \n",
    "plt.plot(denorm_pred,color='red', label='Prediction')\n",
    "plt.plot(denorm_ytest,color='blue', label='Answer')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "#denorm_pred = denormalize(foxconndf, pred)\n",
    "#denorm_ytest = denormalize(foxconndf, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
