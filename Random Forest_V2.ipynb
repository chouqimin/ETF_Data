{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# n_estimators:[100,150,200,250,300,350,400]：决策树的个数，越多越好，但是性能就会越差，至少100左右（具体数字忘记从哪里来的了）可以达到可接受的性能和误差率。 \n",
    "# criterion: [\"gini\",\"entropy\"](default=”gini”)是计算属性的gini(基尼不纯度)还是entropy(信息增益)，来选择最合适的节点。\n",
    "# max_features: [\"auto\",\"sqrt\",\"log2\",\"None\"]\n",
    "# traindata_rate=[0.7,0.8,0.9]\n",
    "n_estimators=[100,150,200,250,300,350,400]\n",
    "criterion=[\"gini\",\"entropy\"]\n",
    "max_features=[\"auto\",\"sqrt\",\"log2\"]\n",
    "traindata_rate=[0.7,0.8,0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_chromsom_value_X(filename):\n",
    "    chromosom_value_X=[]\n",
    "    ETF_train = pd.read_csv(filename)\n",
    "    col_list=list(ETF_train.columns)\n",
    "\n",
    "    for index in range(0,len(col_list)-1):\n",
    "        chromosom_value_X.append([0,1])\n",
    "    return chromosom_value_X\n",
    "\n",
    "def create_chromsom_value_all(filename):\n",
    "    chromosom_value=create_chromsom_value_X(filename)\n",
    "    chromosom_value.append(n_estimators)\n",
    "    chromosom_value.append(criterion)\n",
    "    chromosom_value.append(max_features)\n",
    "    chromosom_value.append(traindata_rate)\n",
    "    return chromosom_value\n",
    "\n",
    "#print(create_chromsom_value_all(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def createrandomList(create_number,category):\n",
    "    list_random = [ random.randint(0,category) for i in range(create_number)]\n",
    "    return(list_random)\n",
    "\n",
    "#init create population chromosome(100)--function input：filename & population, output：population_list \n",
    "def create_population(population):\n",
    "    population_list=[]\n",
    "    for popu in range(population):\n",
    "        chromosome_create=[]\n",
    "        for index in chromosom_value:\n",
    "            chromosome_create.append(index[createrandomList(1,len(index)-1)[0]]) #從chromosom_value隨機產生一個值塞到\n",
    "        population_list.append(chromosome_create)\n",
    "    return population_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 200, 'entropy', 'log2', 0.9]\n"
     ]
    }
   ],
   "source": [
    "chromosom_value=create_chromsom_value_all(filename)\n",
    "ch_1=create_population(1)[0]\n",
    "print(ch_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input \n",
    "# ETF_train = pd.read_csv('0051_random.csv')\n",
    "# col_list=list(ETF_train.columns)\n",
    "\n",
    "# chromosome=create_population(1)[0]\n",
    "\n",
    "def create_x_tmp(ETF_train,col_list,chromosome):\n",
    "    x_tmp=[]\n",
    "    for index in range(0,len(col_list)-1):\n",
    "        if chromosome[index] ==1:\n",
    "            x_tmp.append(ETF_train[col_list[index]])\n",
    "    return x_tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chromsome=create_population(1)[0]\n",
    "filename='0051_random.csv'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import cross_validation, ensemble, preprocessing, metrics\n",
    "\n",
    "def random_forest_model(filename,chromsome):\n",
    "    # 載入資料\n",
    "    ETF_train = pd.read_csv(filename)\n",
    "    col_list=list(ETF_train.columns)\n",
    "\n",
    "    n_estimators_c=chromsome[len(col_list)-1]\n",
    "    criterion_c=chromsome[len(col_list)+0]\n",
    "    max_features_c=chromsome[len(col_list)+1]\n",
    "    traindata_rate=chromsome[len(col_list)+2]\n",
    "\n",
    "\n",
    "    # 建立訓練與測試資料\n",
    "    x_tmp=create_x_tmp(ETF_train,col_list,chromsome)\n",
    "    ETF_X = pd.DataFrame(x_tmp).T\n",
    "    ETF_Y = ETF_train[\"Y\"]\n",
    "\n",
    "    train_X=ETF_X[:round(len(ETF_train)*traindata_rate)]\n",
    "    test_X=ETF_X[round(len(ETF_train)*traindata_rate):]\n",
    "    train_Y=ETF_Y[:round(len(ETF_train)*traindata_rate)]\n",
    "    test_Y=ETF_Y[round(len(ETF_train)*traindata_rate):]\n",
    "\n",
    "    # 建立 random forest 模型\n",
    "    forest = ensemble.RandomForestClassifier(n_estimators = n_estimators_c,criterion=criterion_c,max_features=max_features_c)\n",
    "    forest_fit = forest.fit(train_X, train_Y)\n",
    "\n",
    "    # 預測\n",
    "    test_y_predicted = forest.predict(test_X)\n",
    "\n",
    "    # 績效\n",
    "    accuracy = metrics.accuracy_score(test_Y, test_y_predicted)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46999999999999997"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_model(filename,chromsome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "[1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 300, 'gini', 'auto', 0.8]\n",
      "0.44\n"
     ]
    }
   ],
   "source": [
    "chromsome=create_population(1)[0]\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import cross_validation, ensemble, preprocessing, metrics\n",
    "\n",
    "# 載入資料\n",
    "ETF_train = pd.read_csv('0051_random.csv')\n",
    "col_list=list(ETF_train.columns)\n",
    "\n",
    "n_estimators_c=chromsome[len(col_list)-1]\n",
    "criterion_c=chromsome[len(col_list)+0]\n",
    "max_features_c=chromsome[len(col_list)+1]\n",
    "traindata_rate=chromsome[len(col_list)+2]\n",
    "\n",
    "\n",
    "# 建立訓練與測試資料\n",
    "x_tmp=create_x_tmp(ETF_train,col_list,chromsome)\n",
    "ETF_X = pd.DataFrame(x_tmp).T\n",
    "ETF_Y = ETF_train[\"Y\"]\n",
    "\n",
    "train_X=ETF_X[:round(len(ETF_train)*traindata_rate)]\n",
    "test_X=ETF_X[round(len(ETF_train)*traindata_rate):]\n",
    "train_Y=ETF_Y[:round(len(ETF_train)*traindata_rate)]\n",
    "test_Y=ETF_Y[round(len(ETF_train)*traindata_rate):]\n",
    "\n",
    "\n",
    "# 建立 random forest 模型\n",
    "forest = ensemble.RandomForestClassifier(n_estimators = n_estimators_c,criterion=criterion_c,max_features=max_features_c)\n",
    "forest_fit = forest.fit(train_X, train_Y)\n",
    "\n",
    "# 預測\n",
    "test_y_predicted = forest.predict(test_X)\n",
    "\n",
    "# 績效\n",
    "accuracy = metrics.accuracy_score(test_Y, test_y_predicted)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import cross_validation, ensemble, preprocessing, metrics\n",
    "\n",
    "# 載入資料\n",
    "ETF_train = pd.read_csv('0051_random.csv')\n",
    "\n",
    "# 建立訓練與測試資料\n",
    "x_tmp=[ETF_train[\"OpenPrice\"],ETF_train[\"Volume\"]]\n",
    "ETF_X = pd.DataFrame(x_tmp).T\n",
    "ETF_Y = ETF_train[\"Y\"]\n",
    "\n",
    "train_X=ETF_X[:round(len(ETF_train)*0.8)]\n",
    "test_X=ETF_X[round(len(ETF_train)*0.8):]\n",
    "train_Y=ETF_Y[:round(len(ETF_train)*0.8)]\n",
    "test_Y=ETF_Y[round(len(ETF_train)*0.8):]\n",
    "\n",
    "\n",
    "# 建立 random forest 模型\n",
    "forest = ensemble.RandomForestClassifier(n_estimators = 100)\n",
    "forest_fit = forest.fit(train_X, train_Y)\n",
    "\n",
    "# 預測\n",
    "test_y_predicted = forest.predict(test_X)\n",
    "\n",
    "# 績效\n",
    "accuracy = metrics.accuracy_score(test_Y, test_y_predicted)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_population' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-0072b189225d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mx_tmp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcreate_population\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcreate_population\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mx_tmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mETF_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mx_tmp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'create_population' is not defined"
     ]
    }
   ],
   "source": [
    "x_tmp=[]\n",
    "for index in range(0,len(create_population(1)[0])):\n",
    "    if create_population(1)[0][index] ==1:\n",
    "        x_tmp.append(ETF_train[col_list[index]])\n",
    "x_tmp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
